#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰å…¨æ‰¹é‡æ“ä½œæœåŠ¡
================

æä¾›åˆ†ç»„å°æ‰¹é‡ + é€æ­¥éªŒè¯çš„å®‰å…¨æ‰¹é‡æ“ä½œæ¥å£ï¼Œ
æ”¯æŒæ‰€æœ‰æ•°æ®åŒºå—ï¼ˆTIPã€MARKã€TIPWORDã€TIPCOLORã€TIMEï¼‰çš„æ‰¹é‡æ›´æ–°ã€‚

ç‰¹æ€§ï¼š
- åˆ†ç»„å¤„ç†ï¼šå¤§æ‰¹é‡æ•°æ®åˆ†æˆå°ç»„ï¼Œé™ä½é£é™©
- é€æ­¥éªŒè¯ï¼šæ¯ç»„æ“ä½œåéªŒè¯ç»“æœï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å›é€€
- ç»Ÿä¸€æ¥å£ï¼šæ”¯æŒæ‰€æœ‰æ•°æ®åŒºå—çš„æ‰¹é‡æ“ä½œ
- è¯¦ç»†æŠ¥å‘Šï¼šæä¾›å®Œæ•´çš„æ“ä½œç»Ÿè®¡å’Œé”™è¯¯ä¿¡æ¯
- å®‰å…¨æœºåˆ¶ï¼šè‡ªåŠ¨å¤‡ä»½å’Œå›é€€åŠŸèƒ½
"""

import shutil
from typing import Dict, List, Optional, Union, Any
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path

from .tdx_mark_manager import TdxMarkManager
from .data_service import DataOperationService
from .models import BatchOperationResult, OperationResult
from .constants import DataSection
from .validators import validate_section, validate_stock_code
from .exceptions import ValidationError, TdxMarkException


@dataclass
class SafeBatchConfig:
    """å®‰å…¨æ‰¹é‡æ“ä½œé…ç½®"""
    chunk_size: int = 5                    # æ¯ç»„å¤„ç†çš„æ•°æ®é‡
    success_threshold: float = 100.0       # æˆåŠŸç‡é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
    auto_rollback: bool = True             # è‡ªåŠ¨å›é€€å¤±è´¥çš„ç»„
    continue_on_chunk_failure: bool = True # æŸç»„å¤±è´¥æ—¶æ˜¯å¦ç»§ç»­å¤„ç†åç»­ç»„
    create_summary_report: bool = True     # æ˜¯å¦åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
    validate_before_save: bool = True      # ä¿å­˜å‰æ˜¯å¦éªŒè¯æ•°æ®å®Œæ•´æ€§


@dataclass
class ChunkResult:
    """å•ç»„æ“ä½œç»“æœ"""
    chunk_index: int
    chunk_data: Dict[str, str]
    success: bool
    success_rate: float
    successful_items: List[str] = field(default_factory=list)
    failed_items: List[str] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    backup_path: Optional[str] = None
    rolled_back: bool = False


@dataclass
class SafeBatchResult:
    """å®‰å…¨æ‰¹é‡æ“ä½œå®Œæ•´ç»“æœ"""
    total_items: int
    total_chunks: int
    successful_chunks: int
    failed_chunks: int
    rolled_back_chunks: int
    overall_success_rate: float
    successful_items: List[str] = field(default_factory=list)
    failed_items: List[str] = field(default_factory=list)
    chunk_results: List[ChunkResult] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    
    @property
    def total_successful_items(self) -> int:
        """æˆåŠŸå¤„ç†çš„æ€»é¡¹ç›®æ•°"""
        return len(self.successful_items)
    
    @property
    def total_failed_items(self) -> int:
        """å¤±è´¥çš„æ€»é¡¹ç›®æ•°"""
        return len(self.failed_items)
    
    @property
    def duration(self) -> Optional[float]:
        """æ“ä½œè€—æ—¶ï¼ˆç§’ï¼‰"""
        if self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None


class SafeBatchService:
    """
    å®‰å…¨æ‰¹é‡æ“ä½œæœåŠ¡
    
    æä¾›åˆ†ç»„å°æ‰¹é‡æ“ä½œï¼Œæ”¯æŒè‡ªåŠ¨å›é€€å’Œè¯¦ç»†æŠ¥å‘Š
    """
    
    def __init__(self, manager: Optional[TdxMarkManager] = None):
        """
        åˆå§‹åŒ–å®‰å…¨æ‰¹é‡æœåŠ¡
        
        Args:
            manager: TdxMarkManagerå®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
        """
        self.manager = manager or TdxMarkManager()
        self.service = DataOperationService()
        
    def safe_batch_update(self, 
                         updates: Dict[str, str], 
                         section: str,
                         config: Optional[SafeBatchConfig] = None) -> SafeBatchResult:
        """
        å®‰å…¨çš„æ‰¹é‡æ›´æ–°æ“ä½œ
        
        Args:
            updates: æ›´æ–°æ•°æ®å­—å…¸ {stock_code: value}
            section: æ•°æ®åŒºå—åç§°ï¼ˆMARK/TIP/TIPWORD/TIPCOLOR/TIMEï¼‰
            config: æ‰¹é‡æ“ä½œé…ç½®
            
        Returns:
            SafeBatchResult: å®Œæ•´çš„æ“ä½œç»“æœ
            
        Raises:
            ValidationError: è¾“å…¥éªŒè¯å¤±è´¥
            TdxMarkException: æ“ä½œå¼‚å¸¸
        """
        if config is None:
            config = SafeBatchConfig()
            
        # è¾“å…¥éªŒè¯
        self._validate_inputs(updates, section)
        
        # åˆå§‹åŒ–ç»“æœå¯¹è±¡
        result = SafeBatchResult(
            total_items=len(updates),
            total_chunks=0,
            successful_chunks=0,
            failed_chunks=0,
            rolled_back_chunks=0,
            overall_success_rate=0.0
        )
        
        try:
            # åˆ†ç»„æ•°æ®
            chunks = self._split_into_chunks(updates, config.chunk_size)
            result.total_chunks = len(chunks)
            
            print(f"ğŸš€ å¼€å§‹å®‰å…¨æ‰¹é‡æ“ä½œï¼š{len(updates)} é¡¹æ•°æ®ï¼Œåˆ†ä¸º {len(chunks)} ç»„")
            print(f"ğŸ“Š é…ç½®ï¼šæ¯ç»„ {config.chunk_size} é¡¹ï¼ŒæˆåŠŸç‡é˜ˆå€¼ {config.success_threshold}%")
            
            # é€ç»„å¤„ç†
            for i, chunk_data in enumerate(chunks):
                chunk_result = self._process_chunk(
                    chunk_data, section, i + 1, config
                )
                result.chunk_results.append(chunk_result)
                
                if chunk_result.success:
                    result.successful_chunks += 1
                    result.successful_items.extend(chunk_result.successful_items)
                else:
                    result.failed_chunks += 1
                    result.failed_items.extend(chunk_result.failed_items)
                    result.errors.extend(chunk_result.errors)
                    
                    if chunk_result.rolled_back:
                        result.rolled_back_chunks += 1
                    
                    # æ£€æŸ¥æ˜¯å¦ç»§ç»­å¤„ç†
                    if not config.continue_on_chunk_failure:
                        print(f"â›” ç»„ {i + 1} å¤±è´¥ï¼Œåœæ­¢åç»­å¤„ç†")
                        break
            
            # è®¡ç®—æ€»ä½“æˆåŠŸç‡
            result.overall_success_rate = (
                len(result.successful_items) / result.total_items * 100
                if result.total_items > 0 else 0
            )
            
            result.end_time = datetime.now()
            
            # ç”ŸæˆæŠ¥å‘Š
            if config.create_summary_report:
                self._print_summary_report(result, section)
                
            return result
            
        except Exception as e:
            result.end_time = datetime.now()
            result.errors.append(f"æ‰¹é‡æ“ä½œå¼‚å¸¸: {str(e)}")
            raise TdxMarkException(f"å®‰å…¨æ‰¹é‡æ“ä½œå¤±è´¥: {str(e)}")
    
    def _validate_inputs(self, updates: Dict[str, str], section: str) -> None:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        if not updates:
            raise ValidationError("æ›´æ–°æ•°æ®ä¸èƒ½ä¸ºç©º")
            
        # éªŒè¯åŒºå—åç§°
        validate_section(section)
        
        # éªŒè¯è‚¡ç¥¨ä»£ç 
        for stock_code in updates.keys():
            try:
                validate_stock_code(stock_code, allow_short=True)
            except Exception as e:
                raise ValidationError(f"æ— æ•ˆçš„è‚¡ç¥¨ä»£ç  {stock_code}: {str(e)}")
    
    def _split_into_chunks(self, updates: Dict[str, str], chunk_size: int) -> List[Dict[str, str]]:
        """å°†æ›´æ–°æ•°æ®åˆ†ç»„"""
        items = list(updates.items())
        chunks = []
        
        for i in range(0, len(items), chunk_size):
            chunk = dict(items[i:i + chunk_size])
            chunks.append(chunk)
            
        return chunks
    
    def _process_chunk(self, 
                      chunk_data: Dict[str, str], 
                      section: str, 
                      chunk_index: int,
                      config: SafeBatchConfig) -> ChunkResult:
        """å¤„ç†å•ä¸ªæ•°æ®ç»„"""
        chunk_result = ChunkResult(
            chunk_index=chunk_index,
            chunk_data=chunk_data,
            success=False,
            success_rate=0.0
        )
        
        print(f"ğŸ“¦ å¤„ç†ç¬¬ {chunk_index} ç»„ï¼š{len(chunk_data)} é¡¹æ•°æ®")
        
        # åˆ›å»ºå¤‡ä»½
        try:
            backup_path = self.manager.create_backup()
            chunk_result.backup_path = backup_path
            print(f"ğŸ’¾ å¤‡ä»½å·²åˆ›å»ºï¼š{Path(backup_path).name}")
        except Exception as e:
            chunk_result.errors.append(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {str(e)}")
            return chunk_result
        
        try:
            # åŠ è½½æ•°æ®
            data = self.manager.load_data(create_backup=False)
            
            # æ‰§è¡Œæ‰¹é‡æ›´æ–°
            batch_result = self.service.batch_update(chunk_data, section, data)
            
            # åˆ†æç»“æœ
            chunk_result.success_rate = batch_result.success_rate
            
            for stock_code, success in batch_result.individual_results.items():
                if success:
                    chunk_result.successful_items.append(stock_code)
                else:
                    chunk_result.failed_items.append(stock_code)
            
            chunk_result.errors.extend(batch_result.errors)
            
            # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°æˆåŠŸç‡é˜ˆå€¼
            if chunk_result.success_rate >= config.success_threshold:
                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if config.validate_before_save:
                    validation_result = self.manager.validate_data_integrity(data)
                    if validation_result.get('invalid_codes'):
                        raise Exception(f"æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {validation_result['invalid_codes']}")
                
                # ä¿å­˜æ•°æ®
                self.manager.save_data(data)
                chunk_result.success = True
                print(f"âœ… ç¬¬ {chunk_index} ç»„å®Œæˆï¼ŒæˆåŠŸç‡ï¼š{chunk_result.success_rate:.1f}%")
                
            else:
                # æˆåŠŸç‡ä¸è¾¾æ ‡ï¼Œå›é€€
                if config.auto_rollback:
                    shutil.copy2(backup_path, self.manager.mark_dat_path)
                    chunk_result.rolled_back = True
                    print(f"âš ï¸  ç¬¬ {chunk_index} ç»„æˆåŠŸç‡è¿‡ä½ï¼ˆ{chunk_result.success_rate:.1f}%ï¼‰ï¼Œå·²è‡ªåŠ¨å›é€€")
                else:
                    print(f"âš ï¸  ç¬¬ {chunk_index} ç»„æˆåŠŸç‡è¿‡ä½ï¼ˆ{chunk_result.success_rate:.1f}%ï¼‰ï¼Œæœªè‡ªåŠ¨å›é€€")
                
        except Exception as e:
            # å¼‚å¸¸æ—¶å›é€€
            error_msg = f"ç¬¬ {chunk_index} ç»„å¤„ç†å¼‚å¸¸: {str(e)}"
            chunk_result.errors.append(error_msg)
            
            if config.auto_rollback and chunk_result.backup_path:
                try:
                    shutil.copy2(chunk_result.backup_path, self.manager.mark_dat_path)
                    chunk_result.rolled_back = True
                    print(f"âŒ {error_msg}ï¼Œå·²è‡ªåŠ¨å›é€€")
                except Exception as rollback_error:
                    chunk_result.errors.append(f"å›é€€å¤±è´¥: {str(rollback_error)}")
                    print(f"âŒ {error_msg}ï¼Œå›é€€ä¹Ÿå¤±è´¥äº†")
            else:
                print(f"âŒ {error_msg}")
        
        return chunk_result
    
    def _print_summary_report(self, result: SafeBatchResult, section: str) -> None:
        """æ‰“å°æ“ä½œæ‘˜è¦æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š å®‰å…¨æ‰¹é‡æ“ä½œæ‘˜è¦æŠ¥å‘Š")
        print("="*60)
        print(f"æ•°æ®åŒºå—: {section}")
        print(f"å¼€å§‹æ—¶é—´: {result.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç»“æŸæ—¶é—´: {result.end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"è€—æ—¶: {result.duration:.2f} ç§’")
        print()
        
        print("ğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        print(f"  æ€»æ•°æ®é¡¹: {result.total_items}")
        print(f"  æ€»åˆ†ç»„æ•°: {result.total_chunks}")
        print(f"  æˆåŠŸç»„æ•°: {result.successful_chunks}")
        print(f"  å¤±è´¥ç»„æ•°: {result.failed_chunks}")
        print(f"  å›é€€ç»„æ•°: {result.rolled_back_chunks}")
        print()
        
        print("ğŸ¯ ç»“æœç»Ÿè®¡:")
        print(f"  æˆåŠŸé¡¹ç›®: {result.total_successful_items}")
        print(f"  å¤±è´¥é¡¹ç›®: {result.total_failed_items}")
        print(f"  æ€»ä½“æˆåŠŸç‡: {result.overall_success_rate:.1f}%")
        print()
        
        if result.failed_items:
            print("âŒ å¤±è´¥é¡¹ç›®:")
            for item in result.failed_items[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  - {item}")
            if len(result.failed_items) > 10:
                print(f"  ... è¿˜æœ‰ {len(result.failed_items) - 10} ä¸ªå¤±è´¥é¡¹ç›®")
            print()
        
        if result.errors:
            print("âš ï¸  é”™è¯¯ä¿¡æ¯:")
            for error in result.errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"  - {error}")
            if len(result.errors) > 5:
                print(f"  ... è¿˜æœ‰ {len(result.errors) - 5} ä¸ªé”™è¯¯")
            print()
        
        print("="*60)
    
    def batch_update_tip(self, updates: Dict[str, str], 
                        config: Optional[SafeBatchConfig] = None) -> SafeBatchResult:
        """æ‰¹é‡æ›´æ–°TIPåŒºå—"""
        return self.safe_batch_update(updates, DataSection.TIP.value, config)
    
    def batch_update_mark(self, updates: Dict[str, str], 
                         config: Optional[SafeBatchConfig] = None) -> SafeBatchResult:
        """æ‰¹é‡æ›´æ–°MARKåŒºå—"""
        return self.safe_batch_update(updates, DataSection.MARK.value, config)
    
    def batch_update_tipword(self, updates: Dict[str, str], 
                           config: Optional[SafeBatchConfig] = None) -> SafeBatchResult:
        """æ‰¹é‡æ›´æ–°TIPWORDåŒºå—"""
        return self.safe_batch_update(updates, DataSection.TIPWORD.value, config)
    
    def batch_update_tipcolor(self, updates: Dict[str, str], 
                             config: Optional[SafeBatchConfig] = None) -> SafeBatchResult:
        """æ‰¹é‡æ›´æ–°TIPCOLORåŒºå—"""
        return self.safe_batch_update(updates, DataSection.TIPCOLOR.value, config)
    
    def batch_update_time(self, updates: Dict[str, str], 
                         config: Optional[SafeBatchConfig] = None) -> SafeBatchResult:
        """æ‰¹é‡æ›´æ–°TIMEåŒºå—"""
        return self.safe_batch_update(updates, DataSection.TIME.value, config)


# ä¾¿æ·å‡½æ•°
def create_safe_batch_config(chunk_size: int = 5,
                           success_threshold: float = 100.0,
                           auto_rollback: bool = True,
                           continue_on_failure: bool = True) -> SafeBatchConfig:
    """åˆ›å»ºå®‰å…¨æ‰¹é‡æ“ä½œé…ç½®çš„ä¾¿æ·å‡½æ•°"""
    return SafeBatchConfig(
        chunk_size=chunk_size,
        success_threshold=success_threshold,
        auto_rollback=auto_rollback,
        continue_on_chunk_failure=continue_on_failure
    )


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    safe_service = SafeBatchService()
    
    # é…ç½®æ“ä½œå‚æ•°
    config = create_safe_batch_config(
        chunk_size=3,                # æ¯ç»„3ä¸ªé¡¹ç›®
        success_threshold=100.0,     # 100%æˆåŠŸç‡é˜ˆå€¼
        auto_rollback=True,          # è‡ªåŠ¨å›é€€
        continue_on_failure=True     # ç»§ç»­å¤„ç†åç»­ç»„
    )
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_updates = {
        "600613": "ä¸œé˜¿é˜¿èƒ¶-ä¼˜è´¨æ¶ˆè´¹è‚¡",
        "000001": "å¹³å®‰é“¶è¡Œ-é‡‘èé¾™å¤´", 
        "002415": "æµ·åº·å¨è§†-å®‰é˜²é¾™å¤´",
        "600036": "æ‹›å•†é“¶è¡Œ-ä¼˜è´¨é“¶è¡Œè‚¡",
        "000858": "äº”ç²®æ¶²-ç™½é…’é¾™å¤´"
    }
    
    # æ‰§è¡Œå®‰å…¨æ‰¹é‡æ›´æ–°
    try:
        result = safe_service.batch_update_tip(test_updates, config)
        
        if result.overall_success_rate >= 80:
            print(f"ğŸ‰ æ‰¹é‡æ“ä½œæ•´ä½“æˆåŠŸï¼æˆåŠŸç‡ï¼š{result.overall_success_rate:.1f}%")
        else:
            print(f"âš ï¸  æ‰¹é‡æ“ä½œæˆåŠŸç‡è¾ƒä½ï¼š{result.overall_success_rate:.1f}%")
            
    except Exception as e:
        print(f"âŒ æ‰¹é‡æ“ä½œå¤±è´¥ï¼š{e}")